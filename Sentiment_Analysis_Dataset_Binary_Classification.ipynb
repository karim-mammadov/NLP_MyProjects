{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMkauREY8NFZ6T+XSmtaEH2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karim-mammadov/NLP_MyProjects/blob/main/Sentiment_Analysis_Dataset_Binary_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iw4RA2SlFYIK"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "-gUeSk9KFgNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download dineshpiyasamara/sentiment-analysis-dataset"
      ],
      "metadata": {
        "id": "c6XiZL5hFutU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile"
      ],
      "metadata": {
        "id": "B91NSSgNFygZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with zipfile.ZipFile('/content/sentiment-analysis-dataset.zip','r') as zip_ref:\n",
        "  zip_ref.extractall('/content')"
      ],
      "metadata": {
        "id": "wsrsJcsQF1y4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/sentiment_analysis.csv')"
      ],
      "metadata": {
        "id": "7rEXXBisGDHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "metadata": {
        "id": "9rdop4trGrd9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['tweet'].head(5))"
      ],
      "metadata": {
        "id": "RCWakPw-LEGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df['text_length'] = df['tweet'].apply(lambda x: len(str(x)))\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.hist(df['text_length'], bins=50, color='skyblue')\n",
        "plt.xlabel('Mətn uzunluğu')\n",
        "plt.ylabel('Sətir sayı')\n",
        "plt.title('Mətn uzunluqlarının paylanması')\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "PvIfkt4bLROs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud\n",
        "\n",
        "all_text = \" \".join(df['tweet'].astype(str))\n",
        "\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(all_text)\n",
        "\n",
        "plt.figure(figsize=(15,7))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "yVaEBN5ELZEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "short_texts = df[df['text_length'] < 30]\n",
        "print(\"Çox qısa mətnlər:\\n\", short_texts['tweet'].head(10))\n",
        "\n",
        "long_texts = df[df['text_length'] > 300]\n",
        "print(\"Çox uzun mətnlər:\\n\", long_texts['tweet'].head(10))"
      ],
      "metadata": {
        "id": "5Z9CnIkmLpJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "metadata": {
        "id": "Q0tkfN6xGy8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "  text = text.lower()\n",
        "  text = re.sub(r'http\\S+', '', text)\n",
        "  text = re.sub(r'@\\S+', '', text)\n",
        "  text = re.sub(r'[^a-z\\s]', '', text)\n",
        "  text = ' '.join([word for word in text.split() if word not in stop_words])\n",
        "  return text\n",
        "df['cleaned_text'] = df['tweet'].apply(clean_text)"
      ],
      "metadata": {
        "id": "7u-YtUbtHRox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df['cleaned_text'], df['label'], test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "0-02J1LbH_5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
        "\n",
        "X_train_vec = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_test_vec = tfidf_vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "wslT4ObtIXPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "model = LogisticRegression()\n",
        "\n",
        "model.fit(X_train_vec, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test_vec)\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "VnH5YFBNIfSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Positive', 'Negative'])\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "XQE7P05rIvSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rbU90JIKKnYF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}